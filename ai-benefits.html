<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>AI Benefits in Social Media Moderation</title>

  <!-- Enlace a Google Fonts para tipografía -->
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">

  <!-- Enlace a Font Awesome para iconos -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  
  <!-- Enlace al CSS del proyecto -->
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <!-- Navigation -->
  <div class="nav">
    <div class="inner">
      <div class="navlinks">
        <a href="index.html">Home</a>
        <a href="human-impact.html">Human Impact</a>
        <a href="ai-benefits.html">AI Benefits</a>
        <a href="ethical-challenges.html">Ethical Challenges</a>
      </div>
    </div>
  </div>

  <!-- AI Benefits Section -->
  <!-- AI Benefits Section -->
<section id="ai-benefits">
  <div class="wrap">

    <div class="sectionTitleRow">
      <div>
        <div class="eyebrow">Future Outlook</div>
        <h2>When AI Becomes a Shield — Not a Shortcut</h2>
        <p class="lead">
          The long-term promise of AI moderation is not just faster enforcement.
          It is a future where <strong>humans are no longer forced to watch traumatic material</strong> to keep platforms safe.
        </p>
      </div>

      <div class="futurePanel reveal" aria-label="Future snapshot">
        <div class="futureTop">
          <div class="futureBadge">
            <i class="fas fa-robot"></i>
            <span>Trajectory</span>
          </div>
          <div class="futureMeta">
            <span class="metaDot"></span>
            <span>Human exposure → near zero</span>
          </div>
        </div>

        <div class="futureFacts">
          <div class="fact">
            <div class="factNum" data-count="1">0</div>
            <div class="factLbl">Goal</div>
          </div>
          <div class="fact">
            <div class="factNum" data-count="0">0</div>
            <div class="factLbl">Human viewing required</div>
          </div>
          <div class="fact">
            <div class="factNum" data-count="100">0</div>
            <div class="factLbl">Safer by design</div>
          </div>
        </div>

        <p class="panelSmall">
          If AI can reliably detect the worst content before a human sees it, moderation stops being “dirty work” and becomes a safeguarded system.
        </p>
      </div>
    </div>

    <img src="/mnt/data/67933ea3-121a-40c4-931b-32e1a4dc6a78.png" alt="AI and Moderation" class="ai-image reveal">

    <div class="projectGrid">
      <div class="glassCard reveal">
        <h3><i class="fas fa-shield-alt"></i> The End Goal: No Human Trauma</h3>
        <p>
          In the most ethical future scenario, advanced AI models handle the first (and hardest) line of defense:
          detecting graphic violence, self-harm content, sexual exploitation, and extreme harassment with high reliability.
          Human involvement shifts from <strong>watching traumatic content</strong> to <strong>oversight and auditing</strong>.
        </p>
      </div>

      <div class="glassCard reveal">
        <h3><i class="fas fa-route"></i> How We Get There</h3>
        <ul class="cleanList">
          <li><strong>Multi-modal models</strong> that understand text + image + video context together.</li>
          <li><strong>Confidence thresholds</strong> so only uncertain edge cases are escalated.</li>
          <li><strong>Red-team testing</strong> to stress models with adversarial content.</li>
          <li><strong>Continuous updates</strong> as language, memes, and harmful tactics evolve.</li>
        </ul>
      </div>
    </div>

    <div class="glassCard reveal" style="margin-top:18px;">
      <h3><i class="fas fa-hand-holding-heart"></i> What “Human-in-the-Loop” Should Mean</h3>
      <p>
        Today, “human-in-the-loop” often means humans absorb the worst content to correct AI errors.
        In a better future, it means the opposite: humans stay at a safe distance and only intervene for
        <strong>policy decisions</strong>, <strong>appeals</strong>, <strong>quality control</strong>, and <strong>fairness checks</strong>.
      </p>
    </div>

    <h3 style="margin-top:26px;">Key Benefits in a Mature AI Future</h3>
    <div class="aiBenefitsGrid">
      <div class="benefitCard reveal">
        <div class="benefitIcon"><i class="fas fa-eye-slash"></i></div>
        <h4>Near-Zero Exposure</h4>
        <p>AI filters harmful material before it ever reaches a human moderator’s screen.</p>
      </div>

      <div class="benefitCard reveal">
        <div class="benefitIcon"><i class="fas fa-bolt"></i></div>
        <h4>Instant Triage</h4>
        <p>Real-time detection reduces the time harmful content stays visible to users.</p>
      </div>

      <div class="benefitCard reveal">
        <div class="benefitIcon"><i class="fas fa-balance-scale"></i></div>
        <h4>More Consistency</h4>
        <p>With good governance, AI can reduce “moderator mood” variability and uneven enforcement.</p>
      </div>

      <div class="benefitCard reveal">
        <div class="benefitIcon"><i class="fas fa-search"></i></div>
        <h4>Auditable Systems</h4>
        <p>Humans can focus on auditing decisions instead of witnessing harm directly.</p>
      </div>
    </div>

    <div class="glassCard reveal" style="margin-top:18px;">
      <h3><i class="fas fa-exclamation-triangle"></i> Critical Condition</h3>
      <p>
        This future only works if AI is deployed with strict safeguards: transparency, appeal mechanisms,
        bias monitoring, and clear accountability. Otherwise, “automation” risks becoming a tool for silent censorship.
      </p>
    </div>

    <div class="ctaRow" style="margin-top:18px;">
      <a href="ethical-challenges.html" class="btn primary">
        <i class="fas fa-gavel"></i> See the Ethical Challenges
      </a>
      <a href="human-impact.html" class="btn">
        <i class="fas fa-comment-dots"></i> Return to Human Impact
      </a>
    </div>

  </div>
</section>


  <!-- Footer Section -->
  <footer>
    <div class="wrap">
      <p>&copy; 2026 Pablo Mateo. All rights reserved.</p>
    </div>
  </footer>

  <!-- JS Link at the end of body -->
  <script src="scripts/main.js"></script>
</body>
</html>
